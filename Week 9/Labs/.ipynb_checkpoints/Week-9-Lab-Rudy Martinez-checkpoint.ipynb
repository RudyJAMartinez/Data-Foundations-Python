{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning and NLP\n",
    "\n",
    "Name: Rudy Martinez\n",
    "\n",
    "abc123: Lpe538\n",
    "\n",
    "Blank notebook to be used for class exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Write code to load the data in the \"iris.csv\" into numpy arrays.\n",
    "\n",
    "The frst 4 columns are the features/attributes. The last column is the\n",
    "class. Simply load the class as a list of strings. Don't forget to convert the\n",
    "dataset into a numpy array. You can use either DictVectorizer or the CSV\n",
    "method on the previous slide to load the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.1,3.5,1.4,0.2,Iris-setosa\n",
      "4.9,3.0,1.4,0.2,Iris-setosa\n",
      "4.7,3.2,1.3,0.2,Iris-setosa\n",
      "4.6,3.1,1.5,0.2,Iris-setosa\n",
      "5.0,3.6,1.4,0.2,Iris-setosa\n",
      "5.4,3.9,1.7,0.4,Iris-setosa\n",
      "4.6,3.4,1.4,0.3,Iris-setosa\n",
      "5.0,3.4,1.5,0.2,Iris-setosa\n",
      "4.4,2.9,1.4,0.2,Iris-setosa\n",
      "4.9,3.1,1.5,0.1,Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "with open('iris.csv') as in_file:\n",
    "    count = 0\n",
    "    for row in in_file:\n",
    "        print(row.strip())\n",
    "        count += 1\n",
    "        if count == 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "X_list_dict = []\n",
    "Y_list = []\n",
    "\n",
    "with open('iris.csv') as file:\n",
    "    csv = csv.reader(file, delimiter = ',')\n",
    "\n",
    "    for row in csv:\n",
    "        features = {'feature_1': float(row[0]),\n",
    "                    'feature_2': float(row[1]),\n",
    "                    'feature_3': float(row[2]),\n",
    "                    'feature_4': float(row[3])}\n",
    "        X_list_dict.append(features)\n",
    "        Y_list.append(row[4])\n",
    "        \n",
    "vec = DictVectorizer(sparse = False)\n",
    "X_1 = vec.fit_transform(X_list_dict)\n",
    "Y_1 = np.array(Y_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Using the iris data you loaded in Exercise 1, do the following:\n",
    "\n",
    "- Use train_test_split() to divide the iris dataset. (use 0.2 for the\n",
    "test size). Set random_state to 42.\n",
    "- Train an SVM on the train split and evaluate using accuracy on the\n",
    "test split.\n",
    "- Fiddle with the parameters of the SVM to see how it effects the\n",
    "performance.\n",
    "- Calculate the accuracy on the train split. Is there a difference between the train/test accuracies?\n",
    "\n",
    "Next, try using a different classifier, a random forest, and see how it\n",
    "compares to the SVM\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "Note that this is a toy dataset, so all scores will be high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: 0.9666666666666667\n",
      "Train: 0.925\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import random\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_1, Y_1, test_size = 0.2, random_state = 42)\n",
    "\n",
    "clf = SVC(C = 0.1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "preds_1 = clf.predict(X_val)\n",
    "print(f\"Test: {accuracy_score(y_val, preds_1)}\")\n",
    "\n",
    "preds_2 = clf.predict(X_train)\n",
    "print(f\"Train: {accuracy_score(y_train, preds_2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest - Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: 1.0\n",
      "Train: 1.0\n"
     ]
    }
   ],
   "source": [
    "X_train_, X_val_, y_train_, y_val_ = train_test_split(X_1, Y_1, test_size = 0.2, random_state = 42)\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train_, y_train_)\n",
    "\n",
    "preds_3 = clf.predict(X_val_)\n",
    "print(f\"Test: {accuracy_score(y_val_, preds_3)}\")\n",
    "\n",
    "preds_4 = clf.predict(X_train_)\n",
    "print(f\"Train: {accuracy_score(y_train_, preds_4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "Using the train/test iris dataset split from exercise 2. Train a model on the training dataset using GridSearchCV with the SVC kernel parameters \"rbf\" and \"linear\",and C parameters 0.001, 0.01, 0.1, 1., and 10. Print the training and\n",
    "validation scores for the best set of parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'C': 1.0, 'kernel': 'linear'}\n",
      "Best Score: 0.975\n",
      "\n",
      "Test: 1.0\n",
      "Train: 0.975\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_1, Y_1, test_size = 0.2, random_state = 42)\n",
    "\n",
    "parameters = {'kernel': ('linear', 'rbf'), 'C':[0.001, 0.01, 0.1, 1.,10.]}\n",
    "\n",
    "c = SVC()\n",
    "clf = GridSearchCV(c, parameters, cv = 3)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best Params: {clf.best_params_}\")\n",
    "print(f\"Best Score: {clf.best_score_}\\n\")\n",
    "\n",
    "preds_5 = clf.predict(X_test)\n",
    "print(f\"Test: {accuracy_score(y_test, preds_5)}\")\n",
    "\n",
    "preds_6 = clf.predict(X_train)\n",
    "print(f\"Train: {accuracy_score(y_train, preds_6)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "\n",
    "The tab (\\t) separated file \"sentiment-twitter-data.tsv\" contains tweets annotated for sentiment. Load the data then do the following:\n",
    "\n",
    "- split the dataset into a train/test split.\n",
    "- create a bag of words feature representation for the tweets using the CountVectorizer\n",
    "- Use grid-search (CV) on the train split to find the best C parameters for a LinearSVC classifier. Only test 2 C values to reduce overhead (0.1 and 1.). Also, use a 2-fold CV, i.e., cv=2.\n",
    "- report (print) the accuracy, micro F1, and macro F1 of the final classifier on the test data and train data\n",
    "- How many features were created with the bag of words representation?\n",
    "\n",
    "file path: ./sentiment-twitter-data.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264183816548130816\t15140428\tpositive\tGas by my house hit $3.39!!!! I'm going to Chapel Hill on Sat. :)\n",
      "264249301910310912\t18516728\tnegative\tIranian general says Israel's Iron Dome can't deal with their missiles (keep talking like that and we may end up finding out)\n",
      "264105751826538497\t147088367\tpositive\twith J Davlar 11th. Main rivals are team Poland. Hopefully we an make it a successful end to a tough week of training tomorrow.\n",
      "264094586689953794\t332474633\tnegative\tTalking about ACT's &amp;&amp; SAT's, deciding where I want to go to college, applying to colleges and everything about college stresses me out.\n",
      "254941790757601280\t557103111\tnegative\tThey may have a SuperBowl in Dallas, but Dallas ain't winning a SuperBowl. Not with that quarterback and owner. @S4NYC @RasmussenPoll\n",
      "264169034155696130\t382403760\tneutral\tIm bringing the monster load of candy tomorrow, I just hope it doesn't get all squiched\n",
      "263192091700654080\t344222239\tobjective-OR-neutral\tApple software, retail chiefs out in overhaul: SAN FRANCISCO Apple Inc CEO Tim Cook on Monday replaced the heads... http://t.co/X49ZEOsG\n",
      "263398998675693568\t812957996\tpositive\t@oluoch @victor_otti @kunjand I just watched it! Sridevi's comeback.... U remember her from the 90s?? Sun mornings on NTA ;)\n",
      "260200142420992000\t332530284\tobjective\t#Livewire Nadal confirmed for Mexican Open in February: Rafael Nadal is set to play at the Me... http://t.co/zgUXpcnC #LiveWireAthletics\n",
      "264087629237202944\t61903760\tpositive\t@MsSheLahY I didnt want to just pop up... but yep we have chapel hill next wednesday you should come.. and shes great ill tell her you asked\n"
     ]
    }
   ],
   "source": [
    "# This is a tab seperated file, so with csv reader use delimiter=\"\\t\"\n",
    "with open('./sentiment-twitter-data.tsv') as in_file:\n",
    "    count = 0\n",
    "    for row in in_file:\n",
    "        print(row.strip())\n",
    "        count += 1\n",
    "        if count == 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "with open('sentiment-twitter-data.tsv') as file:\n",
    "    csv = csv.reader(file, delimiter = '\\t')\n",
    "\n",
    "    for row in csv:\n",
    "        features = {'feature_1': float(row[0]),\n",
    "                    'feature_2': float(row[1]),\n",
    "                    'feature_3': row[3]}\n",
    "        X_list_dict.append(features)\n",
    "        Y_list.append(row[2])\n",
    "        \n",
    "vec = DictVectorizer(sparse = False)\n",
    "X_2 = vec.fit_transform(X_list_dict)\n",
    "Y_2 = np.array(Y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_2, Y_2, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "\n",
    "vec = CountVectorizer(ngram_range = 1,1), min_df = 1)\n",
    "cnt_stats = vec.fit()\n",
    "bagOfWords = vec.transform()\n",
    "\n",
    "print(f\"Every feature: {vec.get_feature_names()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-4f225b5fd439>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_list_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feature_3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
