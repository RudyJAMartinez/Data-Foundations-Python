{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning and NLP\n",
    "\n",
    "Name: Rudy Martinez\n",
    "\n",
    "abc123: Lpe538\n",
    "\n",
    "Blank notebook to be used for class exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Write code to load the data in the \"iris.csv\" into numpy arrays.\n",
    "\n",
    "The frst 4 columns are the features/attributes. The last column is the\n",
    "class. Simply load the class as a list of strings. Don't forget to convert the\n",
    "dataset into a numpy array. You can use either DictVectorizer or the CSV\n",
    "method on the previous slide to load the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.1,3.5,1.4,0.2,Iris-setosa\n",
      "4.9,3.0,1.4,0.2,Iris-setosa\n",
      "4.7,3.2,1.3,0.2,Iris-setosa\n",
      "4.6,3.1,1.5,0.2,Iris-setosa\n",
      "5.0,3.6,1.4,0.2,Iris-setosa\n",
      "5.4,3.9,1.7,0.4,Iris-setosa\n",
      "4.6,3.4,1.4,0.3,Iris-setosa\n",
      "5.0,3.4,1.5,0.2,Iris-setosa\n",
      "4.4,2.9,1.4,0.2,Iris-setosa\n",
      "4.9,3.1,1.5,0.1,Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "with open('iris.csv') as in_file:\n",
    "    count = 0\n",
    "    for row in in_file:\n",
    "        print(row.strip())\n",
    "        count += 1\n",
    "        if count == 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "X_list_dict = []\n",
    "Y_list = []\n",
    "\n",
    "with open('iris.csv') as file:\n",
    "    csv = csv.reader(file, delimiter = ',')\n",
    "\n",
    "    for row in csv:\n",
    "        features = {'feature_1': float(row[0]),\n",
    "                    'feature_2': float(row[1]),\n",
    "                    'feature_3': float(row[2]),\n",
    "                    'feature_4': float(row[3])}\n",
    "        X_list_dict.append(features)\n",
    "        Y_list.append(row[4])\n",
    "        \n",
    "vec = DictVectorizer(sparse = False)\n",
    "X_1 = vec.fit_transform(X_list_dict)\n",
    "Y_1 = np.array(Y_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Using the iris data you loaded in Exercise 1, do the following:\n",
    "\n",
    "- Use train_test_split() to divide the iris dataset. (use 0.2 for the\n",
    "test size). Set random_state to 42.\n",
    "- Train an SVM on the train split and evaluate using accuracy on the\n",
    "test split.\n",
    "- Fiddle with the parameters of the SVM to see how it effects the\n",
    "performance.\n",
    "- Calculate the accuracy on the train split. Is there a difference between the train/test accuracies?\n",
    "\n",
    "Next, try using a different classifier, a random forest, and see how it\n",
    "compares to the SVM\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "Note that this is a toy dataset, so all scores will be high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: 0.9666666666666667\n",
      "Train: 0.925\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import random\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_1, Y_1, test_size = 0.2, random_state = 42)\n",
    "\n",
    "clf = SVC(C = 0.1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "preds_1 = clf.predict(X_val)\n",
    "print(f\"Test: {accuracy_score(y_val, preds_1)}\")\n",
    "\n",
    "preds_2 = clf.predict(X_train)\n",
    "print(f\"Train: {accuracy_score(y_train, preds_2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest - Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: 1.0\n",
      "Train: 1.0\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "X_train_, X_val_, y_train_, y_val_ = train_test_split(X_1, Y_1, test_size = 0.2, random_state = 42)\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train_, y_train_)\n",
    "\n",
    "preds_3 = clf.predict(X_val_)\n",
    "print(f\"Test: {accuracy_score(y_val_, preds_3)}\")\n",
    "\n",
    "preds_4 = clf.predict(X_train_)\n",
    "print(f\"Train: {accuracy_score(y_train_, preds_4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "Using the train/test iris dataset split from exercise 2. Train a model on the training dataset using GridSearchCV with the SVC kernel parameters \"rbf\" and \"linear\",and C parameters 0.001, 0.01, 0.1, 1., and 10. Print the training and\n",
    "validation scores for the best set of parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'C': 1.0, 'kernel': 'linear'}\n",
      "Best Score: 0.975\n",
      "\n",
      "Test: 1.0\n",
      "Train: 0.975\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_1, Y_1, test_size = 0.2, random_state = 42)\n",
    "\n",
    "parameters = {'kernel': ('linear', 'rbf'), 'C':[0.001, 0.01, 0.1, 1.,10.]}\n",
    "\n",
    "c = SVC()\n",
    "clf = GridSearchCV(c, parameters, cv = 3)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best Params: {clf.best_params_}\")\n",
    "print(f\"Best Score: {clf.best_score_}\\n\")\n",
    "\n",
    "preds_5 = clf.predict(X_test)\n",
    "print(f\"Test: {accuracy_score(y_test, preds_5)}\")\n",
    "\n",
    "preds_6 = clf.predict(X_train)\n",
    "print(f\"Train: {accuracy_score(y_train, preds_6)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "\n",
    "The tab (\\t) separated file \"sentiment-twitter-data.tsv\" contains tweets annotated for sentiment. Load the data then do the following:\n",
    "\n",
    "- split the dataset into a train/test split.\n",
    "- create a bag of words feature representation for the tweets using the CountVectorizer\n",
    "- Use grid-search (CV) on the train split to find the best C parameters for a LinearSVC classifier. Only test 2 C values to reduce overhead (0.1 and 1.). Also, use a 2-fold CV, i.e., cv=2.\n",
    "- report (print) the accuracy, micro F1, and macro F1 of the final classifier on the test data and train data\n",
    "- How many features were created with the bag of words representation?\n",
    "\n",
    "file path: ./sentiment-twitter-data.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264183816548130816\t15140428\tpositive\tGas by my house hit $3.39!!!! I'm going to Chapel Hill on Sat. :)\n",
      "264249301910310912\t18516728\tnegative\tIranian general says Israel's Iron Dome can't deal with their missiles (keep talking like that and we may end up finding out)\n",
      "264105751826538497\t147088367\tpositive\twith J Davlar 11th. Main rivals are team Poland. Hopefully we an make it a successful end to a tough week of training tomorrow.\n",
      "264094586689953794\t332474633\tnegative\tTalking about ACT's &amp;&amp; SAT's, deciding where I want to go to college, applying to colleges and everything about college stresses me out.\n",
      "254941790757601280\t557103111\tnegative\tThey may have a SuperBowl in Dallas, but Dallas ain't winning a SuperBowl. Not with that quarterback and owner. @S4NYC @RasmussenPoll\n",
      "264169034155696130\t382403760\tneutral\tIm bringing the monster load of candy tomorrow, I just hope it doesn't get all squiched\n",
      "263192091700654080\t344222239\tobjective-OR-neutral\tApple software, retail chiefs out in overhaul: SAN FRANCISCO Apple Inc CEO Tim Cook on Monday replaced the heads... http://t.co/X49ZEOsG\n",
      "263398998675693568\t812957996\tpositive\t@oluoch @victor_otti @kunjand I just watched it! Sridevi's comeback.... U remember her from the 90s?? Sun mornings on NTA ;)\n",
      "260200142420992000\t332530284\tobjective\t#Livewire Nadal confirmed for Mexican Open in February: Rafael Nadal is set to play at the Me... http://t.co/zgUXpcnC #LiveWireAthletics\n",
      "264087629237202944\t61903760\tpositive\t@MsSheLahY I didnt want to just pop up... but yep we have chapel hill next wednesday you should come.. and shes great ill tell her you asked\n"
     ]
    }
   ],
   "source": [
    "# This is a tab seperated file, so with csv reader use delimiter=\"\\t\"\n",
    "with open('./sentiment-twitter-data.tsv') as in_file:\n",
    "    count = 0\n",
    "    for row in in_file:\n",
    "        print(row.strip())\n",
    "        count += 1\n",
    "        if count == 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "X_text = []\n",
    "y = []\n",
    "\n",
    "\n",
    "with open('sentiment-twitter-data.tsv') as file:\n",
    "    csv = csv.reader(file, delimiter = '\\t')\n",
    "\n",
    "    for row in csv:\n",
    "        X_text.append(row[3])\n",
    "        y.append(row[2])\n",
    "\n",
    "X_text = np.array(X_text)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the Data (Train / Test Split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "X_text_train, X_text_test, y_train, y_test = train_test_split(X_text, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use grid-search (CV) on the train split to find the best C parameters for a LinearSVC classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=LinearSVC(), param_grid={'C': [0.1, 1.0]})"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec = CountVectorizer(ngram_range = (1,1), min_df = 1)\n",
    "\n",
    "X_train = vec.fit_transform(X_text_train)\n",
    "X_test = vec.transform(X_text_test)\n",
    "\n",
    "svc = LinearSVC()\n",
    "params = {\"C\": [0.1, 1.]}\n",
    "\n",
    "clf = GridSearchCV(svc, params, cv = 2)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Report (print) the accuracy, micro F1, and macro F1 of the final classifier on the test data and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.46595877576514677\n",
      "F1 Micro Score: 0.46595877576514677\n",
      "F1 Micro Score: 0.38576934100208116\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_test)\n",
    "print(f\"Accuracy Score: {accuracy_score(y_test, preds)}\")\n",
    "\n",
    "F1_Micro = f1_score(y_test, preds, average = 'micro')\n",
    "print(f\"F1 Micro Score: {F1_Micro}\")\n",
    "\n",
    "F1_Macro = f1_score(y_test, preds, average = 'macro')\n",
    "print(f\"F1 Micro Score: {F1_Macro}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a bag of words feature representation for the tweets using the CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Content (First 1000): \n",
      "\n",
      " {'gas': 7462, 'by': 3388, 'my': 12453, 'house': 8685, 'hit': 8497, '39': 441, 'going': 7739, 'to': 18593, 'chapel': 3821, 'hill': 8474, 'on': 13306, 'sat': 16151, 'iranian': 9281, 'general': 7517, 'says': 16187, 'israel': 9335, 'iron': 9294, 'dome': 5669, 'can': 3499, 'deal': 5134, 'with': 20214, 'their': 18304, 'missiles': 12056, 'keep': 10082, 'talking': 17970, 'like': 10836, 'that': 18241, 'and': 1580, 'we': 19903, 'may': 11650, 'end': 6248, 'up': 19310, 'finding': 6885, 'out': 13468, 'davlar': 5091, '11th': 89, 'main': 11357, 'rivals': 15642, 'are': 1783, 'team': 18076, 'poland': 14244, 'hopefully': 8627, 'an': 1564, 'make': 11367, 'it': 9350, 'successful': 17658, 'tough': 18736, 'week': 19940, 'of': 13160, 'training': 18800, 'tomorrow': 18653, 'about': 1034, 'act': 1107, 'amp': 1549, 'deciding': 5173, 'where': 20035, 'want': 19798, 'go': 7703, 'college': 4283, 'applying': 1738, 'colleges': 4287, 'everything': 6460, 'stresses': 17570, 'me': 11726\n"
     ]
    }
   ],
   "source": [
    "cnt_stats = vec.fit(X_text)\n",
    "bagOfWords = vec.transform(X_text)\n",
    "\n",
    "print(f\"Vocabulary Content (First 1000): \\n\\n {cnt_stats.vocabulary_}\"[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many features were created with the bag of words representation? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Count: 20898\n",
      "Bag of Words Shape: (8002, 20898)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Feature Count: {len(vec.get_feature_names())}\")\n",
    "print(f\"Bag of Words Shape: {bagOfWords.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
